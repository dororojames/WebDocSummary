<html>
 <body>
  <div>
   <div class="article_content_inner" font="size_0" id="CMS_wrapper">
    <p aid="61">
     现在气势旺盛的人工智能技术，是以机器学习类神经网络为主流的。虽然募资中的创业家和不同投资哲学的风险资本家满嘴都是人工智能，仿佛世界上所有的问题都即将被人工智能解决，但机器学习本质上并不适合我常说的「1%问题」（1% problem）。
    </p>
    <p aid="62">
     我所谓的「1%问题」，是指虽然只有极低的机率会出现极端状况，但一但出现极端状况，其后果往往非常严重，以致于让整体回报期望值跌落为负值。
    </p>
    <p aid="63">
     简单以数学解释的话，我们可以假设一个抽签游戏。签筒中有99只白签和1只黑签，抽中白签的话可以得到美金$100，抽中黑签则得赔美金$9,900，那么这个抽签游戏的净回报期望值为美金$0：
    </p>
    <blockquote>
     <p aid="64">
      99% × $100 + 1% × （−$9,900）＝$0
     </p>
    </blockquote>
    <p aid="65">
     基本上这是一个不赚也不赔的游戏，理性的金融思考逻辑下，任何人都不应该玩这个游戏，因为期望回报为$0，但波动性大于0（有99%机会可能赚钱、有1%机会可能赔钱），比起啥都不做（波动性为0）就可以稳稳的赚到（或赔掉）$0来说应该是一个比较不具吸引力的游戏。
    </p>
    <p aid="66">
     如果上面这个游戏在抽到黑签时必须要赔出超过$9,900的金额，游戏的回报期望值就会变成负值，成为一个不管什么状况下，理性的金融人都不应该参与的游戏。
    </p>
    <p aid="67">
     接下来，我们把这个99%正确率的场景对应到影像辨识，也正是机器学习最早出现突破的范畴。
    </p>
    <p aid="68">
     类神经网络的主要算法其实在很早以前就已经存在，但实际的应用很有限，除了现任脸书AI长的Yann LeCun大神当年在贝尔实验室开发的支票手写辨识机器得到广泛的运用以外，大部分通用影像辨识仍然错误率很高而且速度奇慢无比。二十一世纪前十年，关于电脑永远无法击败人脑的说法常常采用一个简单的例子：人类的小孩没什么知识，但只要看过猫这种动物几次，不用特别学习就可以十拿九稳地辨认出任何外贸的猫来，但这么简单的问题电脑却常常挣扎半天还是频频出错。
    </p>
    <p aid="69">
     但是在研究者发现使用绘图芯片（GPU）进行类神经网络运算的速度，远比用中央处理器（CPU）快很多后，事情开始有了爆发性的进展。2012年的
     <a href="https://en.wikipedia.org/wiki/ImageNet">
      ImageNet
     </a>
     影像辨识大赛（ILSVRC，ImageNet Large Scale Visual Recognition Challenge）中，一个深层卷积网络达成16%的辨识错误率，两年后的赢家则一举突破10%来到7%，隔年2015年年底，机器终于超越人类平均5%错误率的辨识能力来到3.6%，2017年的ILSVRC大赛的38支队伍里更是有高达29支都成功掼破5%——看来在各种影像辨识的任务中，使用任劳任怨的机器取代任性的人类已经是不可逆的进程？
    </p>
    <p aid="70">
     但是以上的论述中都只讨论到错误的
     <strong>
      机率
     </strong>
     ，并没有讨论到各种不同的场景的
     <strong>
      后果
     </strong>
     ，这里我们要引入刚才定义的「1%问题」，来查看现有机器学习式的人工智能系统一个很大的陷阱。
    </p>
    <div class="dnd-atom-wrapper type-image context-smg_800xauto_er">
     <div class="dnd-legend-wrapper">
      <p class="meta">
       中国学校课堂中将安装「慧眼（smart eye）」，上课恍神、不专心通通逃不过机器法眼，透过人脸辨识监控学生专心程度，还会被列为成绩评量依据。（图/截自unsplash）
      </p>
     </div>
    </div>
    <h3 class="subtitle3">
     <strong>
      场景一：传统保全
     </strong>
    </h3>
    <p aid="71">
     传统保全使用人类实况监看保全摄影系统，电影或电视影集中也常常出现这样的场景：两三个穿着警卫或警察制服的人盯着十几个分割屏幕，结果一聊天分心，让正义的伙伴或者变态杀人狂成功避过监视进入保全区域。
    </p>
    <p aid="72">
     保全不可能做到100%毫无疏漏，因此这门生意本来就是机率问题。聘用更多人监看电视就可以降低疏漏率，但是边际效用下降，成本上升。在保户能够接受的费用范围内，保全用户和保全公司在合约的框架下接受一定的总体疏漏机率，在上面追加同样是机率问题的保险制度和再保制度，从而得到一个可行的生意模式。
    </p>
    <p aid="73">
     如果使用影像辨识系统来取代坐在屏幕前监看的人类，成本多半可以降低，而且疏漏率更是远比会打瞌睡和偷懒的人类低。因此保全用户可以享受更高的安全，保全公司也有机会赚到更多的钱，尽管疏漏率仍然不会降到0%。
    </p>
    <p aid="74">
     这是一个真正有用的机器学习应用场景。
    </p>
    <h3 class="subtitle3">
     <strong>
      场景二：行事历自动调度
     </strong>
    </h3>
    <p aid="75">
     我们风险资本家的每天的日常就是一场接着一场的会议，但是不同于企业内部会议只要排时间，我们的会议是四散在各地，中间穿杂着各种电话会议，外加大量的外地出差，这表示跟会议对象确认会议时间排进行事历是一个非常耗时的事情，邮件一来一回可能花两天都还排不好一场会议。
    </p>
    <p aid="76">
     传统的解决方案是聘用秘书或者助理，好的秘书或者助理会根据会议重要性、敏感性、时区、合伙人飞行状况、班机延误风险⋯⋯等各种因素，来和对方进行适当的会议时间、地点和方式协商。
    </p>
    <p aid="77">
     当然这样等级的秘书或者助理很贵，不是大家都负担得起的，我自己常常遇到会议对象的秘书其实都不那么专业（也就是不那么贵），把事情搞砸的次数也不算少。我们自己
     <a href="file:///C:/Users/User/Downloads/hardwareclub.co">
      Hardware Club
     </a>
     因为旗下管理基金总规模还不大，所以并没有特别编列聘用秘书或助理的预算，大多是合伙人自己调度，也因此在巴黎办公室，很多时候晚上公司年轻同仁们都下班了，却还看得到合伙人在这较不花大脑的时段回着邮件，排着下趟出差的会议。
    </p>
    <p aid="78">
     因此我可以理解当年多家知名风险管理公司们——包含
     <a href="https://www.dcm.com/">
      DCM Ventures
     </a>
     、
     <a href="http://firstmarkcap.com/">
      FirstMark Capital
     </a>
     、
     <a href="https://twosigmaventures.com/">
      Two Sigma Ventures
     </a>
     和愿景基金成立之前的软银资本（Softbank Capital）等——进行投资并大肆吹捧
     <a href="https://x.ai/">
      x.ai
     </a>
     这间位于纽约的新创。
    </p>
    <p aid="79">
     x.ai使用机器学习，用电脑秘书自动分析来信内容，并以自然语言回信请求安排会议，然后根据对方回应的文本内容（时间冲突、地点冲突、时区错误⋯⋯等）进行新的时间和地点提案，最后成功达成共识后就自动登录进用户的行事历。
    </p>
    <p aid="80">
     最终理想状态是机器跟机器对话，因为这样一来就不需要分析自然语言，可以直接对行事历和交换变量。但是在抵达这个境界之前，一定会有很多状况是机器跟人对话，不管是跟当事人还是跟秘书或助理，所以能够理解前因后果和对话背景的自然语言人工智能能力就变得很重要。
    </p>
    <p aid="81">
     但在我看来，x.ai的商业考量从第一天开始就有逻辑上的缺陷：会忙到需要秘书或助理帮忙协调行事历的人，正是因为行事历项目又多又重要，才会
     <a href="http://kotowaza-allguide.com/ne/nekonotemokaritai.html">
      连猫的爪子也想借来用
     </a>
     。也只有这样的人有诱因去使用x.ai的系统，希望能降低一些成本。
    </p>
    <p aid="82">
     但类神经网络机器学习基本上是一个
     <strong>
      从很大的输入输出数据库，提炼出以简驭繁的模型的方法
     </strong>
     ，是一个缩减信息量的过程，理论上不可能达到100%正确，永远都会有错误或搞砸的部分。如果是刚刚保全系统的使用情境，因为保全用户是分散的，触发保全系统的犯罪行为也是分散的，因此只要维持整个系统的事件机率低于原本使用人类兼看的系统的机率，人工智能的应用就是有意义的。
    </p>
    <p aid="83">
     但是在本使用情境中，x.ai或者其他自动行事历调度系统，就算做到99%正确、比一般律师和助理更可靠，也不见得有意义，因为只要搞错或搞砸的那1%行事历事项是非常关键的人事物（例如：有意投资基金的机构法人、打算收购公司的大企业首席执行官等），可能导致的损失会远远盖过之前因为换成机器而节省下来的金额。
    </p>
    <p aid="84">
     我可以理解为什么分身乏术的风险资本家，有可能因为自己排会议的痛苦经验，而决定自动调度行事历是一个很棒的商业点子，又遇到很厉害的人工智能创业家，因此决定投资。但是我高度怀疑这些风险资本家，今日自己是否仍然仰赖这样的软件服务来安排自己的行程——因为我实在无法想像当一个风险资本家跟基金投资人重要的会议被安排错误时，他可以接受「平均起来这种错误的机率比人类低」的借口。
    </p>
    <div class="dnd-atom-wrapper type-image context-smg_800xauto_er">
     <div class="dnd-legend-wrapper">
      <p class="meta">
       美国亚利桑那州坦佩市曾传出Uber全自动驾驶汽车撞死行人的交通意外（美联社）
      </p>
     </div>
    </div>
    <h3 class="subtitle3">
     <strong>
      场景三：自动驾驶
     </strong>
    </h3>
    <p aid="85">
     上面所提的「平均起来这种错误的机率比人类低」，将我们带到了目前1%问题可能最严重、但偏偏却又是各方瞩目重金押注的场景：自动驾驶。
    </p>
    <p aid="86">
     两年前，当特斯拉首次有用户因为使用自动驾驶而遇难时，莫斯克在推文上表示
     <strong>
      特斯拉的肇事死亡率仍然远低于一般汽车市场总体统计数据
     </strong>
     ，暗示特斯拉的自动驾驶系统在平均来说是比人类驾驶好的，所以不应该被责怪。
    </p>
    <p aid="87">
     但这种很典型的、看似很理性的工程师逻辑忽略了一件很重要的事情：当一百个人开着一百台车，因驾驶人的问题发生一件致死车祸时，其他的九十九人和九十九台车并不会被一概而论。换言之，这个系统是
     <strong>
      分散的
     </strong>
     ，每个驾驶人互相独立不相干。整体来说只要肇事率维持在1%，系统并不会被咎责。
    </p>
    <p aid="88">
     但如果是特斯拉所提供的自动驾驶有着1%的肇事率，
     <strong>
      那就不是一个分布式系统问题，而是一个中央系统的问题
     </strong>
     ，被咎责的是包含其他九十九台安全无恙的车子在内，总共一百台的数量，可能导致的赔偿金或者刑罚也是根据一百台计算。
    </p>
    <p aid="89">
     君不见2009年
     <a href="https://en.wikipedia.org/wiki/2009%E2%80%9311_Toyota_vehicle_recalls">
      美国丰田汽车暴冲致死事件
     </a>
     ，除了造成大量召回以及车厂经济损失，丰田家族继承人也被拖到美国国会面前羞辱，更甭提品牌受到的重创。十个月后当调查结果终于出炉，正式排除丰田的责任，并将多数相关事件的肇事原因归属于驾驶人，但这时对丰田的永久性伤害已经造成。
    </p>
    <p aid="90">
     同理，特斯拉（或者任何车厂的）自动驾驶系统，目标也不能仅仅是肇事率低于大众平均，而是要做到更低的数量级，才能避免1%问题导致全盘皆输。
    </p>
    <h3 class="subtitle3">
     <strong>
      结论
     </strong>
    </h3>
    <p aid="91">
     机器学习类神经网络本质上是一个或然率的系统，用来颠覆
     <strong>
      原本就是创建在或然率上的商业
     </strong>
     （例如侦测信用卡盗刷），是非常适合的，因为只要人工智能的表现能够比既有的或然率优异，业主就能实现更低成本和更高获利。
    </p>
    <p aid="92">
     但如果或然率是结果，而且本质上存在「1%问题」（单一事件可能导致巨大损失），那么就不能单纯用错误率较低的机器学习类神经网络取代，因为只要出现一只黑天鹅，就可以否决所有天鹅都是白色的论点⋯⋯
    </p>
    <p aid="93">
     ＊作者杨建铭（Jerry Yang, CFA）现任巴黎风险资本公司Hardware Club管理合伙人。台湾大学电机学硕士、法国HEC Paris MBA，CFA持证，在亚洲、硅谷和欧洲半导体业十二年，包含创业四年。（更多好文请见作者
     <a href="http://www.jmyang.com/" target="_blank">
      英文博客
     </a>
     ）
    </p>
   </div>
  </div>
 </body>
</html>