<html>
 <body>
  <div>
   <section class="post-content">
    <p>
     <span>
      今天，我們再來研究另一個相關的問題。有些時候，除了找到關鍵詞，我們還希望找到與原文章相似的其他文章。比如，"Google新聞"在主新聞下方，還提供多條相似的新聞。
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032001.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      為了找出相似的文章，需要用到
      <a href="/rd/aHR0cDovL2VuLndpa2lwZWRpYS5vcmcvd2lraS9Db3NpbmVfc2ltaWxhcml0eQ==" target="_blank">
       "餘弦相似性"
      </a>
      （cosine similiarity）。下面，我舉一個例子來説明，什麼是"餘弦相似性"。
     </span>
    </p>
    <p>
     <span>
      為了簡單起見，我們先從句子著手。
     </span>
    </p>
    <div class="cnblogs_code">
     <pre><span>句子A：我喜歡看電視，不喜歡看電影。
句子B：我不喜歡看電視，也不喜歡看電影。</span></pre>
    </div>
    <p>
     <span>
      請問怎樣才能計算上面兩句話的相似程度？
     </span>
    </p>
    <p>
     <span>
      基本思路是：如果這兩句話的用詞越相似，它們的內容就應該越相似。因此，可以從詞頻入手，計算它們的相似程度。
     </span>
    </p>
    <p>
     <span>
      第一步，分詞。
     </span>
    </p>
    <div class="cnblogs_code">
     <pre><span>句子A：我/喜歡/看/電視，不/喜歡/看/<span>電影。
句子B：我</span>/不/喜歡/看/電視，也/不/喜歡/看/電影。</span></pre>
    </div>
    <p>
     <span>
      第二步，列出所有的詞。
     </span>
    </p>
    <p>
     <span>
      第三步，計算詞頻。
     </span>
    </p>
    <div class="cnblogs_code">
     <pre><span>句子A：我 <span>1</span>，喜歡 <span>2</span>，看 <span>2</span>，電視 <span>1</span>，電影 <span>1</span>，不 <span>1</span>，也 <span>0</span><span>。
句子B：我 </span><span>1</span>，喜歡 <span>2</span>，看 <span>2</span>，電視 <span>1</span>，電影 <span>1</span>，不 <span>2</span>，也 <span>1</span>。</span></pre>
    </div>
    <p>
     <span>
      第四步，寫出詞頻向量。
     </span>
    </p>
    <div class="cnblogs_code">
     <pre><span>句子A：[<span>1</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>0</span><span>]
句子B：[</span><span>1</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>1</span>, <span>2</span>, <span>1</span>]</span></pre>
    </div>
    <p>
     <span>
      到這裡，問題就變成了如何計算這兩個向量的相似程度。
     </span>
    </p>
    <p>
     <span>
      我們可以把它們想象成空間中的兩條線段，都是從原點（[0, 0, ...]）出發，指向不同的方向。兩條線段之間形成一個夾角，如果夾角為0度，意味著方向相同、線段重合；如果夾角為90度，意味著形成直角，方向完全不相似；如果夾角為180度，意味著方向正好相反。因此，我們可以通過夾角的大小，來判斷向量的相似程度。夾角越小，就代表越相似。
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032002.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      以二維空間為例，上圖的a和b是兩個向量，我們要計算它們的夾角θ。
      <a href="/rd/aHR0cDovL3poLndpa2lwZWRpYS5vcmcvemgtY24vJUU5JUE0JTk4JUU1JUJDJUE2JUU1JUFFJTlBJUU3JTkwJTg2" target="_blank">
       餘弦定理
      </a>
      告訴我們，可以用下面的公式求得：
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032004.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032003.png"/>
     </span>
    </p>
    <p>
     <span>
      假定a向量是[x1, y1]，b向量是[x2, y2]，那麼可以將餘弦定理改寫成下面的形式：
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032006.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032005.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      數學家已經證明，餘弦的這種計算方法對n維向量也成立。假定A和B是兩個n維向量，A是 [A1, A2, ..., An] ，B是 [B1, B2, ..., Bn] ，則A與B的夾角θ的餘弦等於：
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032007.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      使用這個公式，我們就可以得到，句子A與句子B的夾角的餘弦。
     </span>
    </p>
    <p>
     <span>
      <img alt="" src="http://www.ruanyifeng.com/blogimg/asset/201303/bg2013032008.png"/>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     <span>
      餘弦值越接近1，就表明夾角越接近0度，也就是兩個向量越相似，這就叫"餘弦相似性"。所以，上面的句子A和句子B是很相似的，事實上它們的夾角大約為20.3度。
     </span>
    </p>
    <p>
     <span>
      由此，我們就得到了"找出相似文章"的一種演算法：
     </span>
    </p>
    <div class="cnblogs_code">
     <pre><span>　　（<span>1</span>）使用TF-<span>IDF演算法，找出兩篇文章的關鍵詞；
　　（</span><span>2</span><span>）每篇文章各取出若干個關鍵詞（比如20個），合併成一個集合，計算每篇文章對於這個集合中的詞的詞頻（為了避免文章長度的差異，可以使用相對詞頻）；
　　（</span><span>3</span><span>）生成兩篇文章各自的詞頻向量；
　　（</span><span>4</span>）計算兩個向量的餘弦相似度，值越大就表示越相似。</span></pre>
    </div>
    <p>
     <span>
      "餘弦相似度"是一種非常有用的演算法，只要是計算兩個向量的相似程度，都可以採用它。
     </span>
    </p>
    <p>
     <span>
      下一次，我想談談如何在詞頻統計的基礎上，自動生成一篇文章的摘要。
     </span>
    </p>
    <p>
     <span>
      轉載：
      <a href="/rd/aHR0cDovL3d3dy5ydWFueWlmZW5nLmNvbS9ibG9nLzIwMTMvMDMvY29zaW5lX3NpbWlsYXJpdHkuaHRtbA==" target="_blank">
       http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html
      </a>
     </span>
    </p>
    <p>
     <span>
     </span>
    </p>
    <p>
     關鍵詞：
     <a href="/search/b::55u45Ly8">
      相似
     </a>
     <a href="/search/b::5L2Z5bym">
      餘弦
     </a>
     <a href="/search/b::5Y%2Bl5a2Q">
      句子
     </a>
     <a href="/search/b::5paH56ug">
      文章
     </a>
     <a href="/search/b::55%2Bi6YeP">
      向量
     </a>
     <a href="/search/b::5aS56KeS">
      夾角
     </a>
     <a href="/search/b::5Zac5qyi">
      喜歡
     </a>
     <a href="/search/b::5oiR5Lus">
      我們
     </a>
     <a href="/search/b::6K6h566X">
      計算
     </a>
     <a href="/search/b::5Y%2Bv5Lul">
      可以
     </a>
    </p>
    <p>
     相關推薦：
    </p>
    <p>
     <a href="/a/b15fb085cca73e148f86ab73465eecd1d510bb379abb544b1d2064bde8ca59d6">
      <strong>
       自然語言處理中句子相似度計算的幾種方法
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/b940c864c1da7d644040df1305a560ae20ac2b5b32203ab1d7aa21d5ea661376">
      <strong>
       AI產品經理需要了解的資料知識：餘弦相似度
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/d1c43b60552bec4f301f4ca2ebcf1b9d57be10a4643f0d460b9502901976fad7">
      <strong>
       tf-idf
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/9a9e8e8eecf54c95a77ab07656b584c91aaa69d371198203407eaf4cf1ac7abf">
      <strong>
       Flex 佈局
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/d246f9bcae7cc717d238d492061c2bcf6bb6895d8781b135be5e735b33b04772">
      <strong>
       TF-IDF與餘弦相似性的應用（三）：自動摘要
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/34098135cb7e3282588e0986d5a97e8b21e6266f078fc6d2996e5f16e9c8f20e">
      <strong>
       餘弦相似度計算
      </strong>
     </a>
    </p>
    <p>
     <a href="/a/c050f8a90b5095d09e2634c89beeb9306ec0603aaf678b21ce44a7e1a66bc963">
      <strong>
       餘弦相似度及基於python的三種程式碼實現、與歐氏距離的區別
      </strong>
     </a>
    </p>
   </section>
  </div>
 </body>
</html>