<html>
 <body>
  <div>
   <div class="content" id="articleContent">
    <p>
     本篇部落格，主要是描述一種計算文字相似度的演算法，基於TF-IDF演算法和餘弦相似性。演算法的描述請務必看阮一峰的部落格，不然看不懂本篇部落格，地址：
    </p>
    <p>
     <a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" rel="nofollow">
      http://www.ruanyifeng.com/blog/2013/03/tf-idf.html
     </a>
    </p>
    <p>
     <a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html" rel="nofollow">
      http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html
     </a>
    </p>
    <p>
     在這裡，主要討論具體的程式碼的實現。過程如下：
    </p>
    <ol>
     <li>
      使用TF-IDF演算法，找出兩篇文章的關鍵詞；
     </li>
     <li>
      每篇文章各取出若干個關鍵詞（比如20個），合併成一個集合，計算每篇文章對於這個集合中的詞的詞頻（為了避免文章長度的差異，可以使用相對詞頻）；
     </li>
     <li>
      生成兩篇文章各自的詞頻向量；
     </li>
     <li>
      計算兩個向量的餘弦相似度，值越大就表示越相似。
     </li>
    </ol>
    <p>
     首先，請看此演算法程式碼的檔案結構：
    </p>
    <p>
     <img alt="檔案結構圖" src="https://static.oschina.net/uploads/space/2018/0112/172650_Es1F_3471006.png"/>
    </p>
    <p>
     接下來，是演算法的實現步驟：
    </p>
    <span id="OSC_h2_1">
    </span>
    <h2>
     第一步：使用TF-IDF演算法，找出兩篇文章的關鍵詞
    </h2>
    <pre><code class="language-java">	/**
	 * （1）使用TF-IDF演算法，找出兩篇文章的關鍵詞；
	 * 
	 * @param uri
	 *            待比較的文字的路徑
	 * @return 文字被分詞後，詞的ELementSet集合
	 * @throws IOException
	 */
	private static ElementSet getKeyTerms(String uri) throws IOException {

		// 分詞後，獲得ElementMap集合
		ElementMap em = null;
		String text = Utils.readText(uri);
		em = Utils.tokenizer(text);

		ElementSet es = em.getElementSetOrderbyTf();

		// 計算tf、idf和tf_idf的值
				Double de = (double) ConnectKit.countTatolFromTerm("的")+1;
		for (Element e : es.getElementSet()) {
			// 計算tf
			Double tf = e.getTf() / es.getElementSet().size();
			e.setTf(tf);
			// 計算idf
			Double num = (double) ConnectKit.countTatolFromTerm(e.getTerm());
			Double idf = Math.log10(de / (num+1));
			e.setIdf(idf);
			// 計算tf_idf
			Double tf_idf = tf * idf;
			e.setTf_idf(tf_idf);
		}

		// 將排序的依據更改為tf_idf
		es.orderbyTf_idf();
		System.out.println("第一步:計算詞的tf、idf和tf_idf");
		for (Element e : es.getElementSet()) {
			System.out.println(e.getTerm() + "---tf:" + e.getTf() + "---idf:" + e.getIdf() + "---tf_idf:" + e.getTf_idf());
		}
		return es;
	}</code></pre>
    <p>
     其中的ElementSet和ElementMap是自己封裝的集合類（沒有繼承任何一個集合），分別使用Set和Map作為其屬性，並提供兩者相互轉換的方法。
    </p>
    <span id="OSC_h2_2">
    </span>
    <h2>
     第二步：每篇文章各取出若干個關鍵詞（比如20個），合併成一個集合，計算每篇文章對於這個集合中的詞的詞頻（為了避免文章長度的差異，可以使用相對詞頻）
    </h2>
    <span id="OSC_h2_3">
    </span>
    <h2>
     &amp;
    </h2>
    <span id="OSC_h2_4">
    </span>
    <h2>
     第三步：生成兩篇文章各自的詞頻向量
    </h2>
    <pre><code class="language-java">/**
	 * （2）每篇文章各取出若干個關鍵詞（比如20個），合併成一個集合，
	 * 計算每篇文章對於這個集合中的詞的詞頻（為了避免文章長度的差異，可以使用相對詞頻）； （3）生成兩篇文章各自的詞頻向量；
	 * 
	 * @param es01
	 *            詞的ElementSet的集合
	 * @param es02
	 *            詞的ElementSet的集合
	 * @param percent
	 *            需要用於的計算的詞百分比（相對於所有的詞）
	 * @return Vectors
	 */
	private static Vectors getVectors(ElementSet es01, ElementSet es02, int percent) {

		// （2）每篇文章各取出若干個關鍵詞（比如20個），合併成一個集合，
		// 計算每篇文章對於這個集合中的詞的詞頻（為了避免文章長度的差異，可以使用相對詞頻）；
		percent = Math.abs(percent);
		if (percent &gt; 100)
			percent %= 100;

		int num01 = Math.round(es01.getSize() * ((float) percent / 100));
		int num02 = Math.round(es02.getSize() * ((float) percent / 100));

		if (num01 == 0)
			num01 = 1;
		if (num02 == 0)
			num02 = 1;

		HashSet&lt;String&gt; hs = new HashSet&lt;String&gt;();

		Iterator&lt;Element&gt; it01 = es01.getElementSet().iterator();
		for (int i = 0; i &lt; num01; i++) {
			if (it01.hasNext()) {
				hs.add(it01.next().getTerm());
			}
		}

		Iterator&lt;Element&gt; it02 = es02.getElementSet().iterator();
		for (int i = 0; i &lt; num02; i++) {
			if (it02.hasNext()) {
				hs.add(it02.next().getTerm());
			}
		}

		// （3）生成兩篇文章各自的詞頻向量；
		ElementMap em01 = es01.getElementMap();
		ElementMap em02 = es02.getElementMap();

		List&lt;Double&gt; vector01 = new ArrayList&lt;Double&gt;();
		List&lt;Double&gt; vector02 = new ArrayList&lt;Double&gt;();

		for (String term : hs) {
			if (em01.getElementMap().containsKey(term)) {
				vector01.add(em01.getDataByTerm(term).getTf());
			} else {
				vector01.add(0D);
			}

			if (em02.getElementMap().containsKey(term)) {
				vector02.add(em02.getDataByTerm(term).getTf());
			} else {
				vector02.add(0D);
			}
		}
		System.out.println();
		System.out.println("第二步:分別提取若干個關鍵字，並分別計算兩篇文章的詞頻向量");
		for (Double d : vector01) {
			System.out.print(d + ",");
		}
		System.out.println();
		for (Double d : vector02) {
			System.out.print(d + ",");
		}
		System.out.println();
		System.out.println();
		return new Vectors(vector01, vector02);

	}</code></pre>
    <p>
     其中，Vectors的屬性是兩個向量。
    </p>
    <span id="OSC_h2_5">
    </span>
    <h2>
     第四步：計算兩個向量的餘弦相似度，值越大就表示越相似。
    </h2>
    <pre><code class="language-java">	/**
	 * 計算餘弦相似度
	 * 
	 * @param vs
	 *            Vectors的實現
	 * @return 餘弦相似度的值
	 */
	private static Double getCosSimilarty(Vectors vs) {
		List&lt;Double&gt; list1 = vs.getVector01();
		List&lt;Double&gt; list2 = vs.getVector02();
		Double countScores = 0D;
		Double element = 0D;
		Double denominator1 = 0D;
		Double denominator2 = 0D;
		int index = -1;
		for (Double it : list1) {
			index++;
			Double left = it.doubleValue();
			Double right = list2.get(index).doubleValue();
			element += left * right;
			denominator1 += left * left;
			denominator2 += right * right;
		}
		try {
			countScores = element / Math.sqrt(denominator1 * denominator2);
		} catch (ArithmeticException e) {
			e.printStackTrace();
		}
		return countScores;
	}</code></pre>
    <p>
     到此，演算法就結束了，但是還有兩個重要的點需要提一下，就是如何計算idf值和分詞：
    </p>
    <span id="OSC_h2_6">
    </span>
    <h2>
     如何獲取idf值：
    </h2>
    <pre><code class="language-java">	/**
	 * 
	 * @param url 訪問的地址
	 * @return 訪問的返回值
	 * @throws MalformedURLException
	 * @throws IOException
	 */
	private static Long getTatolFromUrl(String url) throws MalformedURLException, IOException {

		InputStream instream = null;
		BufferedReader rd = null;
		Long tatol = -1L;
		try {
			instream = new URL(url).openStream();
			rd = new BufferedReader(new InputStreamReader(instream, Charset.forName("UTF-8")));
			//使用正則匹配，從網頁中獲取搜尋數資訊
			Pattern pattern = Pattern.compile("百度為您找到相關結果約[0-9-,]+個");
			String s;

			while ((s = rd.readLine()) != null) {
				Matcher matcher = pattern.matcher(s);
				if (matcher.find()) {
					Pattern p = Pattern.compile("[0-9-,]+");
					Matcher m = p.matcher(matcher.group());
					if (m.find()) {
						String str = m.group().replace(",", "");
						tatol = Long.valueOf(str);
						break;
					}
				}
			}
		} finally {
			instream.close();
			rd.close();
		}
		return tatol;
	}

	public static Long countTatolFromTerm(String term) throws IOException {
		int i = 0;
		while(true){
			//因為有時訪問的內容是錯誤的，所以要多次訪問，以得到正確的結果，但是如果重複的次數過多的話，退出程序
			if((i++)==100){
				System.out.println("訪問百度失敗！！");
				System.exit(0);
			};
			//拼接訪問百度的URL
			Long answer = getTatolFromUrl("http://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=1&amp;tn=baidu&amp;wd=" + term);
			if(answer != -1){
				return answer;
			}
		}
	}</code></pre>
    <p>
     類似與爬蟲程式，但是隻是獲取搜尋數。你也許會問，為什麼idf要這麼計算，請看下圖，注意觀察，詞的搜尋數和idf值之間的關係：
    </p>
    <p>
     <img alt="" src="https://static.oschina.net/uploads/space/2018/0112/214016_G6NE_3471006.png"/>
    </p>
    <p>
     可見，但搜尋量變少後，idf值會急劇增大，這樣可以篩選出關鍵詞。當然，這樣的訪問網路的操作，是很耗時的。
    </p>
    <span id="OSC_h2_7">
    </span>
    <h2>
     如何分詞：
    </h2>
    <pre><code class="language-java">	/**
	 * 將傳入的文字進行分詞，然後詞(單個字要被過濾掉)放入ElementMap中
	 * @param text 需要分詞的文字
	 * @return 分好詞的ElementMap集合
	 * @throws IOException
	 */
	public static ElementMap tokenizer(String text) throws IOException {

		Map&lt;String, Data&gt; map = new TreeMap&lt;String, Data&gt;();
		IKAnalyzer analyzer = new IKAnalyzer();
		analyzer.setUseSmart(true);
		TokenStream stream = null;
		try {
			stream = analyzer.tokenStream("", new StringReader(text));
			stream.reset();
			while (stream.incrementToken()) {
				CharTermAttribute charTermAttribute = stream.getAttribute(CharTermAttribute.class);
				String term = charTermAttribute.toString();
				if (term.length() &gt; 1) {
					Data data = new Data();
					data.setTf(1D);
					boolean isContainsKey = map.containsKey(term);
					if (isContainsKey) {
						Data temp = map.get(term);
						data.setTf(temp.getTf() + 1D);
						map.replace(term, temp, data);
					}
					map.put(term, data);
				}
			}
		} finally {
			stream.close();
			analyzer.close();
		}
		ElementMap em = new ElementMap(map);
		
		if(em.getElementMap().isEmpty()){
			throw new NullPointerException();
		}
		return em;
	}</code></pre>
    <p>
     分詞這部分可能很少接觸，這部分需要兩個jar包，在lib檔案中，還可參考部落格：
    </p>
    <p>
     <a href="https://www.cnblogs.com/lyssym/p/4880896.html" rel="nofollow">
      https://www.cnblogs.com/lyssym/p/4880896.html
     </a>
    </p>
    <p>
     本程式的部分程式碼也是出自這篇部落格。
    </p>
    <p>
     到這裡，本篇部落格結束，但是要強調一點，這個演算法並不能用在實際的生產中，因為搜尋數是從網路獲取的，是一個很耗時的過程。本演算法會進一步修改的，原始碼地址（碼雲）：
    </p>
    <p>
     <a href="https://gitee.com/liutaigang/cosineSimilarty.git" rel="nofollow">
      https://gitee.com/liutaigang/cosineSimilarty.git
     </a>
    </p>
    <p>
     通過git獲取。
    </p>
    <p>
     <strong>
      end
     </strong>
    </p>
   </div>
   <p>
    © 著作權歸作者所有
   </p>
  </div>
 </body>
</html>